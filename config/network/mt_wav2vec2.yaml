# instantiate the x-vector network lightning module config object
_target_: src.networks.mt.mt_wav2vec2.MultiTaskWav2vec2ModuleConfig

# pretrained weights of wav2vec model
wav2vec_huggingface_id: "facebook/wav2vec2-base"

# whether to use reset the pretrained weights
# and start from a fresh initialization
reset_weights: false

# initially freeze wav2vec model
wav2vec_initially_frozen: false

# number of steps before the wav2vec model is unfrozen
# (if initially frozen at all)
# if set to null, wav2vec will never be unfrozen
num_frozen_steps: 10_000

# whether to freeze the feature encoder part
# of the network for the whole training run
completely_freeze_feature_extractor: true

# settings for fc head which does pooling and
# speaker classification
stat_pooling_type: "first+cls+learnable"
use_cosine_linear: true  # only if using AAM loss
num_speaker_dimensions: null  # explicitly split encoder dimension for speech and speaker task if not null

# whether to use a split encoder, and if so, how many layers to still share
# before branching
use_multi_branch_encoder: false
num_shared_transformers: 6

# attend on output with spiked ctc pooling (either blank or non-blank token)
enable_ctc_pool_speaker_embedding: false
enable_ctc_pool_no_grad: true
ctc_pool_on_blank_embeddings: false
ctc_blank_idx: ${optim.loss.ctc_blank_idx}

# language recognition head pretrained weights
speech_head_huggingface_id: null

# optional explicit overwrite of embedding size and/or num speakers
# (e.g if you need to load finetuned weights but want to experiment with another
# pooling type in the evaluation or test on a dataset with different num speakers)
explicit_stat_pool_embedding_size: null
explicit_num_speakers: null

# if enabled, gradient checkpointing slows down iteration speed but saves memory
use_gradient_checkpointing: true
